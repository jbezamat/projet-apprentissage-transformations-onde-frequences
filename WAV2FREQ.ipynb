{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Apprentissage Artificiel\n",
    "---\n",
    "Yoann Menanteau, Thomas Saliba, Jérémy Bezamat\n",
    "\n",
    "---\n",
    "\n",
    "## Contexte :\n",
    "Ce projet a été réalisé dans le cadre d'un cours sur l'apprentissage artificiel de la promotion robotique de Bordeaux INP. Il consiste a essayer de trouver la fréquence d'un signal périodique à l'aide d'un réseau de neurones de type ESN (echo state network) fournie par le dépôt [reservoirpy](https://github.com/neuronalX/reservoirpy).\n",
    "\n",
    "## Démarche :\n",
    "Notre démarche consiste dans un premier temps à essayer d'entrainer un réseau de neurones permettant de trouver la fréquence d'un signal périodique basique composé d'une seule sinusoide. Cette première étape nous as permis de bien prendre en main _reservoirpy_. Par la suite, nous avons entrainé un deuxième réseau de neurones mais qui permet cette fois ci de trouver la fréquence d'un signal périodique plus complexe composé d'une somme de sinusoide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ESN\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed used for random values: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed=None):\n",
    "    \"\"\"Making the seed (for random values) variable if None\"\"\"\n",
    "\n",
    "    # Set the seed\n",
    "    if seed is None:\n",
    "        import time\n",
    "        seed = int((time.time()*10**6) % 4294967295)\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except Exception, e:\n",
    "        print \"!!! WARNING !!!: Seed was not set correctly.\"\n",
    "        print \"!!! Seed that we tried to use: \"+str(seed)\n",
    "        print \"!!! Error message: \"+str(e)\n",
    "        seed = None\n",
    "    print \"Seed used for random values:\", seed\n",
    "    return seed\n",
    "\n",
    "\n",
    "## Set a particular seed for the random generator (for example seed = 42), or use a \"random\" one (seed = None)\n",
    "# NB: reservoir performances should be averaged accross at least 30 random instances (with the same set of parameters)\n",
    "seed = 42 #None #42\n",
    "set_seed(seed) #random.seed(seed)\n",
    "\n",
    "time_steps = 600 # Nombre d'échantillons par période\n",
    "nb_periods = 5 # Nombre de périodes\n",
    "n_input_by_freq = 10 # Nombre d'exemples pour chaque fréquence\n",
    "random_coeff = 1000. \n",
    "min_offsetx = -1/random_coeff\n",
    "min_offsety = -1/random_coeff\n",
    "max_offsetx = 1/random_coeff\n",
    "max_offsety = 1/random_coeff\n",
    "min_amplitude = -1/random_coeff\n",
    "max_amplitude = 1/random_coeff\n",
    "# chances = 5# une chance sur 2 qu'une harmonique ne soit pas changée\n",
    "\n",
    "\n",
    "# 30 seems to be enough for initLen with leak_rate=0.3 and reservoir size (resSize) = 300\n",
    "initLen = 30 # number of time steps during which internal activations are washed-out during training\n",
    "# we consider trainLen including the warming-up period (i.e. internal activations that are washed-out when training)\n",
    "max_freq = initLen + 500 # number of time steps during which we train the network\n",
    "#testLen = max_freq # number of time steps during which we test/run the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première étape est de créer un script permettant de générer de manière aléatoire des signaux périodiques sinusoidaux de manière à entrainer le réseau. On génére une seed pour l'aléatoire en se basant sur le temps de sort à avoir une génération la moins répétable possible.\n",
    "\n",
    "Le nombre d'échantillons par période est fixé par la variable `time_steps`. Le nombre de periode est fixé par la variable `nb_periods`. Les variables qui suivent (min_offsetx, min_offsety, etc...) permettent de rajouter un peu de bruits aux tests afin d'être proche d'une situation réelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_in, train_out dimensions (5290, 3000) (5290, 1)\n",
      "test_in, test_out dimensions (5290, 3000) (5290, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "def create_sine(frequency, offsetx, offsety, size, A):\n",
    "    return A * np.sin(2 * np.pi * frequency * np.linspace(0, 1./frequency*size, time_steps*size)+offsetx)+offsety\n",
    "\n",
    "\n",
    "train_out = list(range(1, max_freq))*n_input_by_freq\n",
    "train_in = np.array([create_sine(freq, np.random.uniform(min_offsetx,max_offsetx), np.random.uniform(min_offsety,max_offsety), nb_periods, np.random.uniform(min_amplitude,max_amplitude)) for freq in train_out])\n",
    "\n",
    "train_out = np.asarray(train_out)\n",
    "temp = []\n",
    "for freq in train_out:\n",
    "    temp.append([freq])\n",
    "train_out = np.asarray(temp)\n",
    "\n",
    "print \"train_in, train_out dimensions\", train_in.shape, train_out.shape\n",
    "\n",
    "test_out = list(range(1, max_freq))*n_input_by_freq\n",
    "test_in = np.array([create_sine(freq, np.random.uniform(min_offsetx,max_offsetx), np.random.uniform(min_offsety,max_offsety), nb_periods, np.random.uniform(min_amplitude,max_amplitude)) for freq in train_out])\n",
    "plt.plot(test_in[150])\n",
    "test_out = np.asarray(test_out)\n",
    "temp = []\n",
    "for freq in test_out:\n",
    "    temp.append([freq])\n",
    "test_out = np.asarray(temp)\n",
    "print \"test_in, test_out dimensions\", test_in.shape, test_out.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première partie: Sinusoides simple\n",
    "\n",
    "Dans cette première partie, nous nous sommes concentrés sur la génération d'un réseau pouvant extraire la fréquence d'une simple sinusoide. Pour créer les sinusoides, nous avons implémenté la fonction `create_sine`. Ensuite, le script créé un ensemble d'entrainement grâce aux tableaux `train_in` et `train_out` (le premier servant à stocker l'ensemble des valeurs du sinus discrétisé et le second stockant la fréquence de chacun de ces sinus). \n",
    "\n",
    "On génere `n_input_by_freq` par fréquence en prenant toutes les fréquences allant de 0 à `max_freq`. Chacun de ces sinus est généré avec des valeurs aléatoires pour l'amplitude, la phase et un décalage en y. \n",
    "\n",
    "Les parties du code comme celle ci-dessous permettent de mettre en forme les données avant de les envoyer au réseau de neurones:\n",
    "    \n",
    "    train_out = np.asarray(train_out)\n",
    "    temp = []\n",
    "    for freq in train_out:\n",
    "        temp.append([freq])\n",
    "    train_out = np.asarray(temp)\n",
    "    \n",
    "\n",
    "Ce script affiche également un exemple d'une de ces sinusoides générées. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing spectral radius... default spectral radius before scaling: 2.35001160885\n",
      "spectral radius after scaling 1.25\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 1\n",
    "input_bias = True # add a constant input to 1\n",
    "n_outputs = 1\n",
    "n_reservoir = 300 # number of recurrent units\n",
    "leak_rate = 0.3 # leaking rate (=1/time_constant_of_neurons)\n",
    "spectral_radius = 1.25 # Scaling of recurrent matrix\n",
    "input_scaling = 1. # Scaling of input matrix\n",
    "proba_non_zero_connec_W = 0.2 # Sparsity of recurrent matrix: Perceptage of non-zero connections in W matrix\n",
    "proba_non_zero_connec_Win = 1. # Sparsity of input matrix\n",
    "proba_non_zero_connec_Wfb = 1. # Sparsity of feedback matrix\n",
    "regularization_coef =  1e-8 #None # regularization coefficient, if None, pseudo-inverse is use instead of ridge regression\n",
    "# out_func_activation = lambda x: x\n",
    "\n",
    "N = n_reservoir#100\n",
    "dim_inp = n_inputs #26\n",
    "\n",
    "### Generating random weight matrices with custom method\n",
    "W = np.random.rand(N,N) - 0.5\n",
    "if input_bias:\n",
    "    Win = np.random.rand(N,dim_inp+nb_periods*time_steps) - 0.5\n",
    "else:\n",
    "    Win = np.random.rand(N,dim_inp+nb_periods*time_steps-1) - 0.5\n",
    "Wfb = np.random.rand(N,n_outputs) - 0.5\n",
    "\n",
    "## delete the fraction of connections given the sparsity (i.e. proba of non-zero connections):\n",
    "mask = np.random.rand(N,N) # create a mask Uniform[0;1]\n",
    "W[mask > proba_non_zero_connec_W] = 0 # set to zero some connections given by the mask\n",
    "mask = np.random.rand(N,Win.shape[1])\n",
    "Win[mask > proba_non_zero_connec_Win] = 0\n",
    "\n",
    "## SCALING of matrices\n",
    "# scaling of input matrix\n",
    "Win = Win * input_scaling\n",
    "# scaling of recurrent matrix\n",
    "# compute the spectral radius of these weights:\n",
    "print 'Computing spectral radius...',\n",
    "original_spectral_radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "print \"default spectral radius before scaling:\", original_spectral_radius\n",
    "# rescale them to reach the requested spectral radius:\n",
    "W = W * (spectral_radius / original_spectral_radius)\n",
    "print \"spectral radius after scaling\", np.max(np.abs(np.linalg.eigvals(W)))\n",
    "\n",
    "reservoir = ESN.ESN(lr=leak_rate, W=W, Win=Win, input_bias=input_bias, ridge=regularization_coef, Wfb=None, fbfunc=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du réseau de neurones\n",
    "\n",
    "Le réseau a besoin d'une certaine configuration. Il a besoin de poids synaptiques. On distingue les poids des synapses en entrées et les autres. Les synapses connectent les neurones. Le fait de connecter ou non est aléatoire est définie selon `proba_non_zero_connec_W`, `proba_non_zero_connec_Win`, `proba_non_zero_connec_Wfb`. Les valeurs des synapses `Win` (entrées) et `W` sont définies aléatoirement. `n_inpu` défini le nombre d'entrées et `n_output` le nombre de sorties. Cette dernière est fixée à un puisqu'on cherche à obtenir une fréquence par signal. Le nombre d'input dépend du nombre d'échantillons du signal lui même dépendant de la variable `time_steps`. \n",
    "\n",
    "L'état du réseau dépend de cette formule:\n",
    "x(t+ 1) = (1−α)x(t) +αf(Winu(t+ 1) + Wx(t))\n",
    "y(t) = Wout*x(t)\n",
    "avec x(t) l'état du réservoir selon le temps t, α un hyper-paramètre leak rate, u(t) l'entrée en fonction du temps et y(t) la sortie en fonction du temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_trained = reservoir.train(inputs=[train_in,], teachers=[train_out,], wash_nr_time_step=initLen, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On donne ensuite au réseau les données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************\n",
      "Errors computed over 5290 time steps\n",
      "\n",
      "Mean Squared error (MSE):\t\t3.2253e+04\n",
      "Root Mean Squared error (RMSE):\t\t1.7959e+02\n",
      "\n",
      "Normalized RMSE (based on mean):\t6.7771e-01\n",
      "Normalized RMSE (based on max - min):\t3.4014e-01\n",
      "********************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_pred, internal_pred = reservoir.run(inputs=[test_in,], reset_state=False)\n",
    "errorLen = len(test_out[:]) #testLen #2000\n",
    "mse = np.mean((test_out[:] - output_pred[0])**2) # Mean Squared Error: see https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "rmse = np.sqrt(mse) # Root Mean Squared Error: see https://en.wikipedia.org/wiki/Root-mean-square_deviation for more info\n",
    "nmrse_mean = abs(rmse / np.mean(test_out[:])) # Normalised RMSE (based on mean)\n",
    "nmrse_maxmin = rmse / abs(np.max(test_out[:]) - np.min(test_out[:])) # Normalised RMSE (based on max - min)\n",
    "print(\"\\n********************\")\n",
    "print(\"Errors computed over %d time steps\" % (errorLen))\n",
    "print(\"\\nMean Squared error (MSE):\\t\\t%.4e\" % (mse) )\n",
    "print(\"Root Mean Squared error (RMSE):\\t\\t%.4e\\n\" % rmse )\n",
    "print(\"Normalized RMSE (based on mean):\\t%.4e\" % (nmrse_mean) )\n",
    "print(\"Normalized RMSE (based on max - min):\\t%.4e\" % (nmrse_maxmin) )\n",
    "print(\"********************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats\n",
    "\n",
    "Les résultats de la première étape (avec des sinusoides simples) après avoir données au réseau les données de test sont présentés ci-dessus. Nous n'avons malheureusement pas pu tester notre réseau avec un grand nombre de données d'entrainement car nous n'avions pas de machine assez performante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sine_with_noise(nbperiods):\n",
    "    signal = 0\n",
    "    freqs = []\n",
    "    nb_sin = 2\n",
    "    for i in range(0, nb_sin):\n",
    "        freq = randint(1, max_freq)\n",
    "        freqs.append(freq)\n",
    "    freq_min = min(freqs)\n",
    "    freq_max = max(freqs)\n",
    "    for i in range(0, nb_sin):\n",
    "        s = np.random.uniform(min_amplitude,max_amplitude) * np.sin(2 * np.pi * freqs[i] * \\\n",
    "            np.linspace(0, (1./freq_min)*nb_periods, time_steps*nb_periods)+np.random.uniform(min_offsetx,max_offsetx))\\\n",
    "                +np.random.uniform(min_offsety,max_offsety)\n",
    "        signal += s\n",
    "    return signal, freq_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième partie: Somme de sinusoides\n",
    "\n",
    "Dans cette partie, on génére cette fois ci des signaux périodiques plus complexes pour l'ensemble des données d'entrainement et de test. Ces signaux sont des sommes de sinusoides (avec `nb_sin` sinusoides par signal) créées par la fonction `create_sine_with_noise` présentée ci-dessus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_in, train_out dimensions (529, 3000) (529, 1)\n",
      "test_in, test_out dimensions (529, 3000) (529, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "def list_to_a(l, d):\n",
    "    l = np.asarray(l)\n",
    "    temp = []\n",
    "    for x in l:\n",
    "        if d == 1:\n",
    "            temp.append([x])\n",
    "        else:\n",
    "            temp.append(x)\n",
    "    return np.asarray(temp)\n",
    "\n",
    "n_input = 10*max_freq # pour avoir même nombre de données d'entrainement que le test précédent\n",
    "train_in = []\n",
    "train_out = []\n",
    "for i in range(1, max_freq):\n",
    "    sig, freq = create_sine_with_noise(nb_periods)\n",
    "    train_in.append(sig)\n",
    "    train_out.append(freq)\n",
    "    \n",
    "train_in = list_to_a(train_in, 2)\n",
    "train_out = list_to_a(train_out, 1)\n",
    "\n",
    "print \"train_in, train_out dimensions\", train_in.shape, train_out.shape\n",
    "\n",
    "test_in = []\n",
    "test_out = []\n",
    "for i in range(1, max_freq):\n",
    "    sig, freq = create_sine_with_noise(nb_periods)\n",
    "    test_in.append(sig)\n",
    "    test_out.append(freq)\n",
    "\n",
    "test_in = list_to_a(test_in, 2)\n",
    "test_out = list_to_a(test_out, 1)\n",
    "plt.plot(test_in[10])\n",
    "\n",
    "print \"test_in, test_out dimensions\", test_in.shape, test_out.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_trained = reservoir.train(inputs=[train_in,], teachers=[train_out,], wash_nr_time_step=initLen, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************\n",
      "Errors computed over 529 time steps\n",
      "\n",
      "Mean Squared error (MSE):\t\t2.6425e+06\n",
      "Root Mean Squared error (RMSE):\t\t1.6256e+03\n",
      "\n",
      "Normalized RMSE (based on mean):\t9.4143e+00\n",
      "Normalized RMSE (based on max - min):\t3.2708e+00\n",
      "********************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_pred, internal_pred = reservoir.run(inputs=[test_in,], reset_state=False)\n",
    "errorLen = len(test_out[:]) #testLen #2000\n",
    "mse = np.mean((test_out[:] - output_pred[0])**2) # Mean Squared Error: see https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "rmse = np.sqrt(mse) # Root Mean Squared Error: see https://en.wikipedia.org/wiki/Root-mean-square_deviation for more info\n",
    "nmrse_mean = abs(rmse / np.mean(test_out[:])) # Normalised RMSE (based on mean)\n",
    "nmrse_maxmin = rmse / abs(np.max(test_out[:]) - np.min(test_out[:])) # Normalised RMSE (based on max - min)\n",
    "print(\"\\n********************\")\n",
    "print(\"Errors computed over %d time steps\" % (errorLen))\n",
    "print(\"\\nMean Squared error (MSE):\\t\\t%.4e\" % (mse) )\n",
    "print(\"Root Mean Squared error (RMSE):\\t\\t%.4e\\n\" % rmse )\n",
    "print(\"Normalized RMSE (based on mean):\\t%.4e\" % (nmrse_mean) )\n",
    "print(\"Normalized RMSE (based on max - min):\\t%.4e\" % (nmrse_maxmin) )\n",
    "print(\"********************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats\n",
    "\n",
    "On retrouve ici aussi les résultats du réseau de neurones après lui avoir envoyé les données de test mais cette fois ci avec des signaux périodiques plus complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Ce projet a permis de se familiariser avec les réseaux de neurones de type ESN. Cela a permis de se confronter aux problématiques courantes lors de l'utilisation d'un réseau de neurones dans un but précis. Choisir le format d'entrée, considérer les métriques intéressantes, quel taille de corpus choisir, etc.. Toutes ces questions se posent lorsque l'on cherche à utiliser un réseau de neurones.\n",
    "Lors de ce projet, un générateur de sinusoïdes a été créé de manière à pouvoir fabriquer un signal périodique simple (une sinusoide) ou plus complexe (somme de sinusoides). Avec ce code, il est possible de générer n'importe quel signal périodique étant donné que tout signal peut se résumer à une somme de sinusoides (série de Fourier). Une fois le corpus créé, le réseau de neurones doit être entrainé puis testé. La compléxité réside souvent dans la bonne qualité du corpus d'entrainement. La phase d'entrainement quand à elle ne nécessite qu'une phase de paramètrage.\n",
    "Il est intéressant de se poser la question de l'utilité d'un réseau de neurones dans un contexte comme celui de ce projet. Le problème de passage d'onde vers fréquence est résolu mathématiquement, c'est la transformée de Fourier. Ce calcul est très présent en traitement du signal et donc il éxiste bon nombre de puces et d'algorithmes optimisés pour résoudre le problème de manière rapide et robuste. L'utilisation d'un réseau de neurones pour résoudre un problème qui possède déjà une résolution mathématique connue n'est pas forcément intéressante en terme pratique. Le FPGA est une soultion alternative permettant de potentiellement battre les meilleurs scores de rapidité du réseau de neurones car la stucture est totalement adaptative aux besoins de l'utilisateur. L'implémentation de réseaux de neurones sur FPGA est d'ailleurs au coeur de la recherche actuelle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
